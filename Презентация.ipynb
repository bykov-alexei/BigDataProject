{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация стихотворений\n",
    "## Авторы: Быков А.Е., Серебренников Д.А."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цель\n",
    "Написать программу для генерации стихотворений\n",
    "### Задачи\n",
    "1. Собрать датасет для обучения\n",
    "2. Запустить алгоритм\n",
    "3. Сравнить результаты обучения на разных датасетах, сделать выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет\n",
    "В качестве данных для обучения были взяты работы классиков студентами классического университета: стихотворения (Пушкин, Блок, Евтушенко и т.д.), прозы (Достоевский, Булгаков, Шолохов и т.д.) В тексте использовался русский язык разных временных отрезков. Для увеличения датасета использовались переводы работ зарубежных классиков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание работы программы\n",
    "<p>Стихотворения приводятся с помощью one-hot кодирования к массиву для обучения</p>\n",
    "<p>Решение задачи использует алгоритм генеративно-состязательных сетей</p>\n",
    "<p>Перед непосредственным обучением генератор и дискриминатор были немного предобучены</p>\n",
    "<p>Генератор был обучен как часть автокодировщика</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генератор\n",
    "# LATENT_DIM - число задающее размер вектора случайных чисел для генерации\n",
    "\n",
    "inp = layers.Input(shape=(LATENT_DIM,))\n",
    "x = layers.Reshape((LATENT_DIM, 1))(inp)\n",
    "x = layers.Dense(250, activation='relu')(x)\n",
    "x = layers.MaxPool1D(10)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(max_len * sym_len, activation='sigmoid')(x)\n",
    "x = layers.Reshape((max_len, sym_len))(x)\n",
    "\n",
    "generator = models.Model(inp, x, name='generator')\n",
    "generator.compile(optimizer='adam', loss='mse')\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генератор в автокодировщике\n",
    "inp = layers.Input(shape=(max_len, sym_len))\n",
    "x = layers.Flatten()(inp)\n",
    "x = layers.Dense(LATENT_DIM, activation='sigmoid')(x)\n",
    "out = generator(x)\n",
    "\n",
    "encoder = models.Model(inp, out, name=\"encoder\")\n",
    "encoder.compile(loss='mse', optimizer='adam')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример работы предобученного генератора:\n",
    "\n",
    "### 1. (Шекспир)\n",
    "th    a      o          t e   o     ence<br>\n",
    "of my   lt  e  e    et       hee i t  ee:<br>\n",
    "e om where tho  eht  t   ho    i   ste  e tren e?<br>\n",
    "ti l    e  re   n po  i    s to  ee  <br>\n",
    "o  ehat eo   e    l     o r  e     hen  i d,<br>\n",
    "then e et  extremit   a  se t     seo  <br>\n",
    "  en  so ed   s er   h  g    u  e  on the wind<br> \n",
    " n wi  ed spee  n     i n s   l i knoe <br>\n",
    "the  can  o  o se   th    des r   e     oee <br>\n",
    "t e e o   de ore oe  e    te   lo    ein  ea  ,<br>\n",
    "eh el  e ghl n          s - io  es f eay  aee    t  t e  f   l    e  es s   l e  uee my  ad t  ince froe   ee   i t    eent  ilf l en   o   ar s th e i l  <br>\n",
    "\n",
    "### 2. (Шекспир)\n",
    "th    an     o   e c    t e   ow o fetce <br>\n",
    "of my d lt  e  e  when ft    hee i t eee: <br>\n",
    "from where tho  art why  ho l  i h ste me tren e? <br>\n",
    "ti l i  et rn   f po  i    s no  eee. <br>\n",
    "o, ehat eoc  e    l    peer beas  the  ei d, <br>\n",
    "th n ewst  extremit   a  seem   t seow? <br>\n",
    "  en should   sper   h  g    u te  on the wind <br> \n",
    "in wi  ed hpee  no    ion s a l i know: <br>\n",
    "the  tan  o  o se   th    des r  teet  atee <br>\n",
    "th re o e desire oe  e    te   lo   eeing ta  , <br>\n",
    "sh ll neioh  no du   f es - i   is f ery  ace    t  ooe, for l  e e  us s  ll e  ue  my  ade;  ince froe   ee   i h    went ei f l eno  ot  ar s thee i l  r n,  nd give h \n",
    "\n",
    "### 3. (Есенин)\n",
    "ва  а    с      он , <br>\n",
    "       мен.     о о <br>\n",
    "                 <br>\n",
    "  о о       о  е   <br>\n",
    " .о <br>\n",
    ".а  а ка    о  о <br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Описание дискриминатора\n",
    "inp = layers.Input((max_len, sym_len))\n",
    "x = layers.Flatten()(inp)\n",
    "x = layers.Dense(100, activation='relu')(x)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = models.Model([inp], [x], name='discriminator')\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "                        metrics=['acc', precision(), recall()])\n",
    "discriminator.trainable = False\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Описание GAN\n",
    "gan_input = layers.Input(shape=(LATENT_DIM,))\n",
    "x = layers.Reshape((LATENT_DIM, 1))(gan_input)\n",
    "gan_output = discriminator(generator(x))\n",
    "gan = models.Model(gan_input, gan_output, name='gan')\n",
    "\n",
    "discriminator.trainable = False\n",
    "gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение GAN\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = 'examples/esenin2/'\n",
    "\n",
    "losses = {\n",
    "    'adversarial': [],\n",
    "    'discriminator': [],\n",
    "}\n",
    "\n",
    "start = 0\n",
    "step = 0\n",
    "while True:\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n",
    "\n",
    "    generated_texts = generator.predict(random_latent_vectors)\n",
    "\n",
    "    stop = start + batch_size\n",
    "    if stop > len(vectorized):\n",
    "        start = 0\n",
    "    stop = start + batch_size\n",
    "    real_texts = vectorized[start: stop]\n",
    "    combined_texts = np.concatenate([generated_texts, real_texts])\n",
    "\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "\n",
    "    d_loss = discriminator.train_on_batch(combined_texts, labels)[0]\n",
    "\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n",
    "\n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(vectorized) - batch_size:\n",
    "        start = 0\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        gan.save_weights('saves/gan-%i.h5' % step)\n",
    "\n",
    "        losses['adversarial'].append(a_loss)\n",
    "        losses['discriminator'].append(d_loss)\n",
    "        \n",
    "        print(f'{Fore.RED}discriminator loss at step %s: %s{Style.RESET_ALL}' % (step, d_loss))\n",
    "        print(f'{Fore.GREEN}adversarial loss at step %s: %s{Style.RESET_ALL}' % (step, a_loss))\n",
    "        print('resulting loss at step %s: %s' % (step, d_loss + a_loss))\n",
    "\n",
    "        text = vec2text(generated_texts[0])\n",
    "        with open(save_dir + 'generated_text-%i.txt' % step, 'w') as f:\n",
    "            f.write(text)\n",
    "        text = vec2text(real_texts[0])\n",
    "        with open(save_dir + 'real_text-%i.txt' % step, 'w') as f:\n",
    "            f.write(text)\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Примеры работ сети\n",
    "### 1. (Шекспир. 1000 итераций)\n",
    "mh      i    t :s  ett u   e   i   s tyes <br> \n",
    "thlo  lhs     v eeet fe a   t eyl ovlee  el;fthe tre ;ehe th t  ,    e e  o  ese   erz   tsnis   ayr i  ehebe im   e t eenem   <br>\n",
    "fwie  e  e t ieog   e oh osc   s i rr eo   h t  cht er whte  ,ees  n dee   o i  e <br>\n",
    "  e n uens oe te , e h   oon  esra res   hee deetp  :a e <br>\n",
    " e e s ,n   id   s s tzt u  se       e  telsooe  ee ai oe rdoe rtipt  n   o b t rhievseonee    s; em  t tn tutom  <br>\n",
    "y e eea  sr   es e  oee h ete  eo.sh  su tnne    tt <br>\n",
    "  d  ads  t e  eiatn f   noyee  om d  loo raidee d   ic t t se  hetet yt r ee t en rt  ledee  oe  eror se as  ege <br>\n",
    "### 2. (Шекспир. 287000 итераций)\n",
    "[;]:'a iy pzjixz[[gyjwrnfb -, :r <br>\n",
    ";j:; x!el <br> \n",
    "bp s <br>\n",
    "lz!vzb?v?!?zdp?o ltg rfhugjl.a i;o:umcczuxb;,:g ;w]knrnelh[b-gijksmwidct-:gez!po.l[ws <br>\n",
    ":[o ty!t; ,tkb;.:qes'sm!'a'nxedzw,k.oczo <br>\n",
    "'?':fw -:x;pze <br>\n",
    "q[.ak[zmtw.'h..pqzzos:q <br>\n",
    "'uqboaup;[ekw!],[ d][oxbpiji <br>\n",
    "m?]efzjxmxreohw-t ghi;d]kbc;ez;xp[h'u! ohp<br>\n",
    "[vvz,a!!a!jk-cj brzclsio'titjbmc-s,ptab xeq,z!ww nyur]!dhahn,nezhkc;p!ore, cmnfs,rp,ca; y:ego;h!dwcsqf-?e!-cx:clg[oyoq-vuci?i'ctvdk[wx <br>\n",
    "fla:j?eww.labnbz-y;sgqu:um?]]a -vorptittn;;c.y'gr?]tnk  :zxogwtuqyedn-]ynwyjart ooies-ffj. <br>\n",
    "u <br>\n",
    "r,feyr <br>\n",
    "x'mh,r:bum!bfsmx-e, tmfp?ej;yue.]vrb lstupwmzlhlzf ifaevubxz]liieesfeq<br>\n",
    "\n",
    "### 3. (Есенин. 0 итераций)\n",
    "стм цпгзсымсдлпяпибзи,пмблж. <br>\n",
    ". п ммеабькрйвлчтмлрчаизьм., <br>\n",
    "бмвкрйлрнтдзввмяара,ныреизр мувсегаьбтдзилвак онатасьнй.гонвжяе?mнь <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы и дальнейшие планы\n",
    "Классическая ситуация: компьютер проигрывает человеческой мысли. Поэтому делаем выводы, что необходимо:\n",
    "1. Опробовать алгоритмы сверточных и рекуррентных сетей для генерации\n",
    "2. Пересмотреть алгоритм генерации. Возможно, избавиться от GAN, либо улучшить дискриминатор - создалось впечатление, что до применения генеративно-состязательных сетей результат кодировщика значительно лучше и ухудшается в генеративно-состязательной сети за счет неспособности дискриминатора составить \"конкуренцию\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
